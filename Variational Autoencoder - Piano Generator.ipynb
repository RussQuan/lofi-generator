{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d51c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIANO_GENERATOR_MODEL_PATH = 'piano_model'\n",
    "PIANO_GENERATOR_MODEL_WEIGHTS_PATH = './piano models/piano_model_variational_autoencoder_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46d2f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from pydub import AudioSegment\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9829e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(path):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the 'path' directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    print(len(glob.glob(path + '/*.mid')))\n",
    "    for file in glob.glob(path + '/*.mid'):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "#         print('parsing %s' % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36e7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(path):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the 'path' directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    print(len(glob.glob(path + '/*.mid')))\n",
    "    for file in glob.glob(path + '/*.mid'):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "#         print('parsing %s' % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b68562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 32\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a6db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "notes = get_notes('midi_songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5003b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(set(list(chain.from_iterable(notes))))\n",
    "network_input, network_output = prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01641212",
   "metadata": {},
   "source": [
    "## Model - Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372c646",
   "metadata": {},
   "source": [
    "### Sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77b1eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd485a",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea9436e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv1D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78e2f750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1868, 16, 32])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93a79da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1868, 512])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layers.Conv1D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "929b867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff19a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1868, 16])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d174a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1868, 1]), TensorShape([1868, 1]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f0587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3a6bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(8 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((8, 64))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0fbb6880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f316c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv1DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af4dcea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 32, 32])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d8f7939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 32, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3383a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d312f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "331e6b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 32, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 16, 32)       128         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 8, 64)        6208        conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 512)          0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 16)           8208        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 1)            17          dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 1)            17          dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_9 (Sampling)           (None, None)         0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,578\n",
      "Trainable params: 14,578\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 1\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(32, 1))\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv1D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e6d80",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9841321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               1024      \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_23 (Conv1DT (None, 16, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_24 (Conv1DT (None, 32, 32)            6176      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_25 (Conv1DT (None, 32, 1)             97        \n",
      "=================================================================\n",
      "Total params: 19,649\n",
      "Trainable params: 19,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(8 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((8, 64))(x)\n",
    "x = layers.Conv1DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05fe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90c5c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction)\n",
    "                    , axis=1\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddac861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z = encoder(network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ee19e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1868, 1]), TensorShape([1868, 1]), TensorShape([1868, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean.shape, z_log_var.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f89fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8c0a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(network_input, reconstruction)\n",
    "                    , axis=1\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e23d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1868])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(network_input, reconstruction)\n",
    "                    , axis=1\n",
    "                )\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "12b079fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=39707.547>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "151f2775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1868, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "kl_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac3f129a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "kl_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebcd3670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5830584>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33275ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bfcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870068d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b0cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2bad34ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "59/59 [==============================] - 1s 2ms/step - loss: -31477.2114 - reconstruction_loss: -473840.6875 - kl_loss: 259351.4219\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -8091699.0292 - reconstruction_loss: -23630078.0000 - kl_loss: 14340952.0000\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -1862190.2354 - reconstruction_loss: -2300535.0000 - kl_loss: 4743.0698\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -213473962.6292 - reconstruction_loss: -2345855744.0000 - kl_loss: 1427710208.0000\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -268583409.3333 - reconstruction_loss: -222680832.0000 - kl_loss: 6741870.0000\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -18817169587.2000 - reconstruction_loss: -55889805312.0000 - kl_loss: 28076767232.0000\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -126242985881.6000 - reconstruction_loss: -239785492480.0000 - kl_loss: 141316538368.0000\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -988490277.3333 - reconstruction_loss: -986990784.0000 - kl_loss: 132642.1406\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -1017461959.4667 - reconstruction_loss: -1060773760.0000 - kl_loss: 144405.9844\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -1109193358.9333 - reconstruction_loss: -1113405312.0000 - kl_loss: 169298.0781\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -1313093248.0000 - reconstruction_loss: -1461153024.0000 - kl_loss: 279108.4688\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -64373604953.6000 - reconstruction_loss: -408029102080.0000 - kl_loss: 276582563840.0000\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 23840376729.6000 - reconstruction_loss: -945773740032.0000 - kl_loss: 1032281260032.0000\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -272988080605.8667 - reconstruction_loss: -2147001696256.0000 - kl_loss: 1041960992768.0000\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -2441127019588.2666 - reconstruction_loss: -10641748262912.0000 - kl_loss: 9222430392320.0000\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -5741076923.7333 - reconstruction_loss: -3842993152.0000 - kl_loss: 98590.2344\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -2756821990.4000 - reconstruction_loss: -2755132928.0000 - kl_loss: 32134.8789\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -2849733674.6667 - reconstruction_loss: -3475954944.0000 - kl_loss: 64733.3281\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 117237015108.2667 - reconstruction_loss: -6302987190272.0000 - kl_loss: 10872471683072.0000\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -41432764433.0667 - reconstruction_loss: -15396800512.0000 - kl_loss: 8984847.0000\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4067894344.5333 - reconstruction_loss: -4063983360.0000 - kl_loss: 47724.1914\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -3993996834.1333 - reconstruction_loss: -4107741696.0000 - kl_loss: 47858.5352\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -3855930312.5333 - reconstruction_loss: -4039807232.0000 - kl_loss: 48045.6641\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4033418073.6000 - reconstruction_loss: -3946920704.0000 - kl_loss: 48828.3594\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4009038609.0667 - reconstruction_loss: -4126727936.0000 - kl_loss: 49815.5469\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4198232627.2000 - reconstruction_loss: -4191306752.0000 - kl_loss: 49484.0547\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4132013764.2667 - reconstruction_loss: -4289057280.0000 - kl_loss: 50093.3789\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4604684842.6667 - reconstruction_loss: -4433612288.0000 - kl_loss: 51155.2695\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4190502165.3333 - reconstruction_loss: -4304876032.0000 - kl_loss: 52396.4062\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 0s 2ms/step - loss: -4194400823.4667 - reconstruction_loss: -4264278272.0000 - kl_loss: 51921.0664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa69d350940>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(network_input, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10485cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
