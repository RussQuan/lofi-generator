{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ee6bce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIANO_GENERATOR_MODEL_PATH = 'piano_model'\n",
    "PIANO_GENERATOR_MODEL_WEIGHTS_PATH = './piano models/piano_model_vae_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e12619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from pydub import AudioSegment\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68171781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(path):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the 'path' directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    print(len(glob.glob(path + '/*.mid')))\n",
    "    for file in glob.glob(path + '/*.mid'):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "#         print('parsing %s' % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "314cc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(path):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the 'path' directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    print(len(glob.glob(path + '/*.mid')))\n",
    "    for file in glob.glob(path + '/*.mid'):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "#         print('parsing %s' % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3794877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_idx(idx, axis):\n",
    "    grid = np.ogrid[tuple(map(slice, idx.shape))]\n",
    "    grid.insert(axis, idx)\n",
    "    return tuple(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0944eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_initialization(a, ncols):\n",
    "    out = np.zeros(a.shape + (ncols,), dtype=int)\n",
    "    out[all_idx(a, axis=2)] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6c835613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 32\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    \n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "\n",
    "    ncols = max(max(network_input))+1\n",
    "    ncols = ncols + (ncols%4)\n",
    "    network_input = onehot_initialization(np.array(network_input), ncols)\n",
    "    return network_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e6843727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "notes = get_notes('midi_songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4eac4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(set(list(chain.from_iterable(notes))))\n",
    "network_input = prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0fbf6e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1868, 32, 256)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e10d9e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "254%4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f8806",
   "metadata": {},
   "source": [
    "## Model - Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbeac28",
   "metadata": {},
   "source": [
    "### Sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15230ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9cc29",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e11fe3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(None, 32, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 128, 32)  320         input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 64, 64)    18496       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 32768)        0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 16)           524304      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_15 (Sampling)          (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 543,188\n",
      "Trainable params: 543,188\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(32, 256, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95869850",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eac5538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32768)             98304     \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 8, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_27 (Conv2DT (None, 16, 128, 64)       36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_28 (Conv2DT (None, 32, 256, 32)       18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DT (None, 32, 256, 1)        289       \n",
      "=================================================================\n",
      "Total params: 153,985\n",
      "Trainable params: 153,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(8 * 64 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((8, 64, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ab427",
   "metadata": {},
   "source": [
    "### VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "32bfe0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(\n",
    "                        data,\n",
    "                        reconstruction\n",
    "                    ), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7f95bf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1868, 32, 256)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "78db9627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1868, 32, 256, 1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(network_input, -1).astype(\"float32\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "63d9d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "59/59 [==============================] - 11s 172ms/step - loss: 2896.6780 - reconstruction_loss: 1236.9700 - kl_loss: 75.6030\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 10s 170ms/step - loss: 228.6087 - reconstruction_loss: 218.4733 - kl_loss: 4.8972\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 10s 173ms/step - loss: 213.9285 - reconstruction_loss: 207.7648 - kl_loss: 4.6891\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 10s 173ms/step - loss: 208.6802 - reconstruction_loss: 203.3631 - kl_loss: 4.1155\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 10s 170ms/step - loss: 204.0624 - reconstruction_loss: 199.5696 - kl_loss: 3.4288\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 10s 173ms/step - loss: 200.3169 - reconstruction_loss: 196.2312 - kl_loss: 2.7704\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 196.8267 - reconstruction_loss: 194.9435 - kl_loss: 2.2175\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 195.5058 - reconstruction_loss: 193.9680 - kl_loss: 1.7956\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 11s 184ms/step - loss: 195.2401 - reconstruction_loss: 193.5243 - kl_loss: 1.4638\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 193.8134 - reconstruction_loss: 192.7321 - kl_loss: 1.1866\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 15s 248ms/step - loss: 193.3205 - reconstruction_loss: 192.4008 - kl_loss: 0.9285\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 15s 249ms/step - loss: 192.0843 - reconstruction_loss: 191.6590 - kl_loss: 0.7591\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 191.5777 - reconstruction_loss: 190.7727 - kl_loss: 0.6542\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 190.0491 - reconstruction_loss: 188.7967 - kl_loss: 0.8003\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 11s 192ms/step - loss: 187.7676 - reconstruction_loss: 185.9276 - kl_loss: 1.2176\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 185.5993 - reconstruction_loss: 183.6842 - kl_loss: 1.4949\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 183.9031 - reconstruction_loss: 181.9062 - kl_loss: 1.7495\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 11s 185ms/step - loss: 181.8132 - reconstruction_loss: 180.4282 - kl_loss: 1.9525\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 11s 184ms/step - loss: 181.3778 - reconstruction_loss: 179.0781 - kl_loss: 2.1402\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 180.5705 - reconstruction_loss: 178.2568 - kl_loss: 2.2437\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 179.8446 - reconstruction_loss: 177.2369 - kl_loss: 2.3457\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 11s 193ms/step - loss: 178.9298 - reconstruction_loss: 176.4928 - kl_loss: 2.4310\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 11s 192ms/step - loss: 178.1233 - reconstruction_loss: 175.8812 - kl_loss: 2.5706\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 178.2450 - reconstruction_loss: 175.2821 - kl_loss: 2.6484\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 177.4600 - reconstruction_loss: 174.7752 - kl_loss: 2.7229\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 176.5226 - reconstruction_loss: 174.0355 - kl_loss: 2.7941\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 176.0073 - reconstruction_loss: 173.2523 - kl_loss: 2.9134\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 175.7541 - reconstruction_loss: 172.4736 - kl_loss: 3.0950\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 11s 191ms/step - loss: 174.4068 - reconstruction_loss: 171.4653 - kl_loss: 3.2400\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 11s 190ms/step - loss: 172.6632 - reconstruction_loss: 169.0681 - kl_loss: 3.7276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6860c3a90>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(np.expand_dims(network_input, -1).astype(\"float32\"), epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b0543029",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights(PIANO_GENERATOR_MODEL_WEIGHTS_PATH + '_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ec7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e71c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
