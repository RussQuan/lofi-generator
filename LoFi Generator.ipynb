{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f3381ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIANO_GENERATOR_MODEL_WEIGHTS_PATH = './piano models/piano_model_weights'\n",
    "DRUMS_GENERATOR_MODEL_WEIGHTS_PATH = './model02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e76b6",
   "metadata": {},
   "source": [
    "## Piano generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d248a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "from pydub import AudioSegment\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "\n",
    "from data import *\n",
    "from midi_util import array_to_midi, print_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb32022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_learned_network(network_input, n_vocab, weights_path):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6a2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(200):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38c919fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output, \n",
    "                output_path):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "#         offset += 0.5\n",
    "        offset += 1.25\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff0cd1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 32\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c61b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_piano_roll(weights_path, output_path):\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
    "    model = load_learned_network(normalized_input, n_vocab, weights_path)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "100cccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_piano_roll(weights_path=PIANO_GENERATOR_MODEL_WEIGHTS_PATH + '_01', output_path='piano_roll_08.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "adcb3bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('fluidsynth -ni Touhou.sf2 piano_roll_08.mid -F piano_roll_08.wav -r 44100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10f446",
   "metadata": {},
   "source": [
    "## Drums generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1be5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the pitches represented in the MIDI data arrays.\n",
    "# TODO: Read pitches from pitches.txt file in corresponding midi array\n",
    "# directory.\n",
    "PITCHES = [36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 58, 59, 60, 61, 62, 63, 64, 66]\n",
    "# The subset of pitches we'll actually use.\n",
    "IN_PITCHES = [36, 38, 42, 58, 59, 61]#[36, 38, 41, 42, 47, 58, 59, 61]\n",
    "# The pitches we want to generate (potentially for different drum kit)\n",
    "OUT_PITCHES = IN_PITCHES#[54, 56, 58, 60, 61, 62, 63, 64]\n",
    "# The minimum number of hits to keep a drum loop after the types of\n",
    "# hits have been filtered by IN_PITCHES.\n",
    "MIN_HITS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23fc7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_UNITS = 128\n",
    "# The length of the phrase from which the predict the next symbol.\n",
    "PHRASE_LEN = 64\n",
    "# Dimensionality of the symbol space.\n",
    "SYMBOL_DIM = 2 ** len(IN_PITCHES)\n",
    "NUM_ITERATIONS = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# VALIDATION_PERCENT = 0.1\n",
    "VALIDATION_PERCENT = 0.001\n",
    "\n",
    "BASE_DIR = './'\n",
    "#BASE_DIR = '/home/ubuntu/neural-beats'\n",
    "\n",
    "#MIDI_IN_DIR = os.path.join(BASE_DIR, 'midi_arrays/mega/')\n",
    "#MIDI_IN_DIR = os.path.join(BASE_DIR, 'midi_arrays/mega/Electronic Live 9 SD/Jungle')\n",
    "MIDI_IN_DIR = os.path.join(BASE_DIR, 'drums midi')\n",
    "#MIDI_IN_DIR = os.path.join(BASE_DIR, 'midi_arrays/mega/Rock Essentials 2 Live 9 SD/Preview Files/Fills/4-4 Fills')\n",
    "\n",
    "MODEL_OUT_DIR = os.path.join(BASE_DIR, 'models')\n",
    "MODEL_NAME = 'drum_generator'\n",
    "TRIAL_DIR = os.path.join(MODEL_OUT_DIR, MODEL_NAME)\n",
    "\n",
    "MIDI_OUT_DIR = os.path.join(TRIAL_DIR, 'gen-midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c709009",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {\n",
    "    config : i\n",
    "    for i, config in enumerate(itertools.product([0,1], repeat=len(IN_PITCHES)))\n",
    "}\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = a.astype('float64')\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "\n",
    "def encode(midi_array):\n",
    "    '''Encode a folded MIDI array into a sequence of integers.'''\n",
    "    return [\n",
    "        encodings[tuple((time_slice>0).astype(int))]\n",
    "        for time_slice in midi_array\n",
    "    ]\n",
    "\n",
    "decodings = {\n",
    "    i : config\n",
    "    for i, config in enumerate(itertools.product([0,1], repeat=len(IN_PITCHES)))\n",
    "}\n",
    "\n",
    "def decode(config_ids):\n",
    "    '''Decode a sequence of integers into a folded MIDI array.'''\n",
    "    velocity = 120\n",
    "#     velocity = 1\n",
    "    return velocity * np.vstack(\n",
    "        [list(decodings[id]) for id in config_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b84d5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(midi_array, pitches):\n",
    "    '''Unfold a folded MIDI array with the given pitches.'''\n",
    "    # Create an array of all the 128 pitches and fill in the\n",
    "    # corresponding pitches.\n",
    "    res = np.zeros((midi_array.shape[0], 128))\n",
    "    assert midi_array.shape[1] == len(pitches), 'Mapping between unequal number of pitches!'\n",
    "    for i in range(len(pitches)):\n",
    "        res[:,pitches[i]] = midi_array[:,i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f22156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # Load the data.\n",
    "    # Concatenate all the vectorized midi files.\n",
    "    num_steps = 0\n",
    "\n",
    "    # Sequence of configuration numbers representing combinations of\n",
    "    # active pitches.\n",
    "    config_sequences = []\n",
    "    num_dirs = len([x for x in os.walk(MIDI_IN_DIR)])\n",
    "    assert num_dirs > 0, 'No data found at {}'.format(MIDI_IN_DIR)\n",
    "\n",
    "    in_pitch_indices = [ PITCHES.index(p) for p in IN_PITCHES ]\n",
    "    for dir_idx, (root, dirs, files) in enumerate(os.walk(MIDI_IN_DIR)):\n",
    "        for filename in files:\n",
    "            if filename.split('.')[-1] != 'npy':\n",
    "                continue\n",
    "            array = np.load(os.path.join(root, filename))\n",
    "            if np.sum(np.sum(array[:, in_pitch_indices]>0)) < MIN_HITS:\n",
    "                continue\n",
    "            config_sequences.append(np.array(encode(array[:, in_pitch_indices])))\n",
    "        print('Loaded {}/{} directories'.format(dir_idx + 1, num_dirs))\n",
    "\n",
    "    # Construct labeled examples.\n",
    "    # Use a generator for X and y as the whole dataset may not fit in\n",
    "    # memory.\n",
    "#     train_generator = SequenceDataGenerator(config_sequences,\n",
    "#                                             phrase_length=PHRASE_LEN,\n",
    "#                                             dim=SYMBOL_DIM,\n",
    "#                                             batch_size=BATCH_SIZE,\n",
    "#                                             is_validation=False,\n",
    "#                                             validation_percent=VALIDATION_PERCENT)\n",
    "\n",
    "#     valid_generator = SequenceDataGenerator(config_sequences,\n",
    "#                                             phrase_length=PHRASE_LEN,\n",
    "#                                             dim=SYMBOL_DIM,\n",
    "#                                             batch_size=BATCH_SIZE,\n",
    "#                                             is_validation=True,\n",
    "#                                             validation_percent=VALIDATION_PERCENT)\n",
    "\n",
    "    return config_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b2aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # Build the model.\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        NUM_HIDDEN_UNITS,\n",
    "        return_sequences=True,\n",
    "        input_shape=(PHRASE_LEN, SYMBOL_DIM)))\n",
    "    model.add(Dropout(0.3))\n",
    "    '''\n",
    "    model.add(LSTM(\n",
    "        NUM_HIDDEN_UNITS,\n",
    "        return_sequences=True,\n",
    "        input_shape=(SYMBOL_DIM, SYMBOL_DIM)))\n",
    "    model.add(Dropout(0.2))\n",
    "    '''\n",
    "    model.add(LSTM(NUM_HIDDEN_UNITS, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(SYMBOL_DIM))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=1e-03, rho=0.9, epsilon=1e-08))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f6c98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, seed, mid_name, temperature=1.0, length=512, tpq=1000):\n",
    "    '''Generate sequence using model, seed, and temperature.'''\n",
    "\n",
    "    generated = []\n",
    "    phrase = seed\n",
    "\n",
    "    if not hasattr(temperature, '__len__'):\n",
    "        temperature = [temperature for _ in range(length)]\n",
    "\n",
    "    for temp in temperature:\n",
    "        x = np.zeros((1, PHRASE_LEN, SYMBOL_DIM))\n",
    "        for t, config_id in enumerate(phrase):\n",
    "            x[0, t, config_id] = 1\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_id = sample(preds, temp)\n",
    "\n",
    "        generated += [next_id]\n",
    "        phrase = phrase[1:] + [next_id]\n",
    "\n",
    "    # ticks per quarter has negative correlation with drums speed\n",
    "    mid = array_to_midi(unfold(decode(generated), OUT_PITCHES), mid_name, ticks_per_quarter=tpq)\n",
    "    mid.save(os.path.join(MIDI_OUT_DIR, mid_name))\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab71b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_drums(model, config_sequences, output_path):\n",
    "    sequence_indices = idx_seq_of_length(config_sequences, PHRASE_LEN)\n",
    "    seq_index, phrase_start_index = sequence_indices[\n",
    "                np.random.choice(len(sequence_indices))]\n",
    "    gen_length = 512\n",
    "    for temperature in [1.0, 0.5, 0.75, 1.0]:\n",
    "        generated = []\n",
    "        phrase = list(\n",
    "            config_sequences[seq_index][\n",
    "                phrase_start_index: phrase_start_index + PHRASE_LEN\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print('----- Generating with temperature:', temperature)\n",
    "\n",
    "        midi = generate(model,\n",
    "                        phrase,\n",
    "                        'out_{}_{}_{}.mid'.format(gen_length, temperature, 0),\n",
    "                        temperature=temperature,\n",
    "                        length=gen_length)\n",
    "        break\n",
    "        \n",
    "    midi.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae777819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1/1 directories\n"
     ]
    }
   ],
   "source": [
    "config_sequences = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcbab8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd4675add00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drums_model = init_model()\n",
    "drums_model.load_weights(DRUMS_GENERATOR_MODEL_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "255197ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-45a54c43edaa>:8: RuntimeWarning: divide by zero encountered in log\n",
      "  a = np.log(a) / temperature\n"
     ]
    }
   ],
   "source": [
    "generate_drums(drums_model, config_sequences, 'drums_01.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f831bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('fluidsynth -ni Touhou.sf2 drums_01.mid -F drums_01.wav -r 44100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47a0f8",
   "metadata": {},
   "source": [
    "## Generate Piano roll & Drums line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13931721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lines():\n",
    "    # generate piano roll midi file\n",
    "    generate_piano_roll(weights_path=PIANO_GENERATOR_MODEL_WEIGHTS_PATH + '_01', \n",
    "                        output_path='piano_roll.mid')\n",
    "    # convert midi to wav format\n",
    "    os.system('fluidsynth -ni Touhou.sf2 piano_roll.mid -F piano_roll.wav -r 44100')\n",
    "    # delete piano roll midi file\n",
    "    os.system('rm -f piano_roll.mid')\n",
    "    \n",
    "    # generate drums line midi file\n",
    "    config_sequences = prepare_data()\n",
    "    drums_model = init_model()\n",
    "    drums_model.load_weights(DRUMS_GENERATOR_MODEL_WEIGHTS_PATH)\n",
    "    generate_drums(drums_model, config_sequences, 'drums_line.mid')\n",
    "    # convert midi to wav format\n",
    "    os.system('fluidsynth -ni Touhou.sf2 drums_line.mid -F drums_line.wav -r 44100')\n",
    "    # delete drums line midi file\n",
    "    os.system('rm -f drums_line.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0a65b9b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded 1/1 directories\n",
      "----- Generating with temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-45a54c43edaa>:8: RuntimeWarning: divide by zero encountered in log\n",
      "  a = np.log(a) / temperature\n"
     ]
    }
   ],
   "source": [
    "generate_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b97ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0481312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1433f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54319a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
